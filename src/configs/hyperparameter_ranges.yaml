dqn_hyperparameters:
  learning_rate:
    type: float
    min: 0.00005
    max: 0.01
    
  gamma:
    type: float
    min: 0.90       # Narrower range
    max: 0.9999       # Was: 0.999
    
  epsilon_start:
    type: float
    min: 0.3        # Narrower range
    max: 1.0
    
  epsilon_min:
    type: float
    min: 0.01
    max: 0.1        # Was: 0.2
    
  epsilon_decay:
    type: float
    min: 0.99
    max: 0.99999      # Was: 0.9999
    
  batch_size:
    type: int_discrete
    values: [8,16,32,64,128,256]      # Only 2 options (was: [16, 32, 64, 128])
    
  target_update_freq:
    type: int_discrete
    values: [5, 10, 20, 30, 50, 75, 100, 150, 200]      # Only 2 options (was: [10, 20, 30, 50, 100])
    
  memory_size:
    type: int_discrete
    values: [5000, 10000, 20000, 50000, 100000, 200000]  # Only 2 options (was: [2000, 5000, 10000, 15000, 20000])
    
  dueling_network:
    type: bool
    values: [true, false]        # Only true to simplify (was: [true, false])

reward_weights:
  energy_satisfaction_weight:
    type: float
    min: 0.2        # Narrower range
    max: 5.0        # Was: 3.0
    
  energy_cost_weight:
    type: float
    min: 0.01        # Narrower range
    max: 2.0        # Was: 1.0
    
  penalty_skipped_vehicle:
    type: float
    min: 5.0       # Narrower range
    max: 500.0      # Was: 200.0
    
  reward_assigned_vehicle:
    type: float
    min: 1.0       # Narrower range
    max: 200.0       # Was: 100.0

archetypes:
  cost_minimizer:
    description: "Extreme minimization of energy costs"
    energy_cost_weight: [1.0, 2.0]        # ≥1.0 para ser clasificado como cost_minimizer
    energy_satisfaction_weight: [0.2, 0.9] # ≤1.0 para ser clasificado como cost_minimizer
    penalty_skipped_vehicle: [5.0, 50.0]
    reward_assigned_vehicle: [1.0, 30.0]
    
  satisfaction_maximizer:
    description: "Customer satisfaction above all else"
    energy_satisfaction_weight: [3.6, 5.0] # >4.0 para ser clasificado como satisfaction_maximizer
    energy_cost_weight: [0.01, 0.45]       # <0.5 para ser clasificado como satisfaction_maximizer
    penalty_skipped_vehicle: [100.0, 500.0]
    reward_assigned_vehicle: [50.0, 200.0]
    
  urgency_focused:
    description: "Never leave vehicles unattended"
    penalty_skipped_vehicle: [201.0, 500.0] # >200.0 para ser clasificado como urgency_focused
    energy_satisfaction_weight: [2.0, 4.0]
    reward_assigned_vehicle: [50.0, 99.0]   # <100.0 para no confundir con efficiency_focused
    energy_cost_weight: [0.1, 0.8]
    
  efficiency_focused:
    description: "Maximum throughput and assignments"
    reward_assigned_vehicle: [101.0, 200.0] # >100.0 para ser clasificado como efficiency_focused
    energy_satisfaction_weight: [1.0, 3.0]
    penalty_skipped_vehicle: [20.0, 199.0]  # <200.0 para no confundir con urgency_focused
    energy_cost_weight: [0.2, 0.99]         # <1.0 para no confundir con cost_minimizer
    
  balanced_optimizer:
    description: "Optimal cost-satisfaction balance"
    energy_satisfaction_weight: [1.1, 3.9]  # Entre 1.0 y 4.0 (rango medio)
    energy_cost_weight: [0.5, 0.99]         # Entre 0.5 y 1.0 (rango medio)
    penalty_skipped_vehicle: [50.0, 199.0]  # Entre 50 y 200 (rango medio)
    reward_assigned_vehicle: [20.0, 99.0]