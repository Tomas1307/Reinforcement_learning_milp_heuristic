dqn_hyperparameters:
  learning_rate:
    type: float
    min: 0.00005
    max: 0.01
    
  gamma:
    type: float
    min: 0.90       # Narrower range
    max: 0.9999       # Was: 0.999
    
  epsilon_start:
    type: float
    min: 0.3        # Narrower range
    max: 1.0
    
  epsilon_min:
    type: float
    min: 0.01
    max: 0.1        # Was: 0.2
    
  epsilon_decay:
    type: float
    min: 0.99
    max: 0.99999      # Was: 0.9999
    
  batch_size:
    type: int_discrete
    values: [8,16,32,64,128,256]      # Only 2 options (was: [16, 32, 64, 128])
    
  target_update_freq:
    type: int_discrete
    values: [5, 10, 20, 30, 50, 75, 100, 150, 200]      # Only 2 options (was: [10, 20, 30, 50, 100])
    
  memory_size:
    type: int_discrete
    values: [5000, 10000, 20000, 50000, 100000, 200000]  # Only 2 options (was: [2000, 5000, 10000, 15000, 20000])
    
  dueling_network:
    type: bool
    values: [true, false]        # Only true to simplify (was: [true, false])

reward_weights:
  energy_satisfaction_weight:
    type: float
    min: 0.2        # Narrower range
    max: 5.0        # Was: 3.0
    
  energy_cost_weight:
    type: float
    min: 0.01        # Narrower range
    max: 2.0        # Was: 1.0
    
  penalty_skipped_vehicle:
    type: float
    min: 5.0       # Narrower range
    max: 500.0      # Was: 200.0
    
  reward_assigned_vehicle:
    type: float
    min: 1.0       # Narrower range
    max: 200.0       # Was: 100.0

archetypes:
  cost_destroyer:
    description: "Extreme minimization of energy costs"
    energy_cost_weight: [1.0, 2.0]
    energy_satisfaction_weight: [0.2, 1.0]
    penalty_skipped_vehicle: [5.0, 50.0]
    reward_assigned_vehicle: [1.0, 30.0]
    
  satisfaction_maximizer:
    description: "Customer satisfaction above all else"
    energy_satisfaction_weight: [3.0, 5.0]
    energy_cost_weight: [0.01, 0.3]
    penalty_skipped_vehicle: [100.0, 500.0]
    reward_assigned_vehicle: [50.0, 200.0]
    
  balanced_elite:
    description: "Optimal cost-satisfaction balance"
    energy_satisfaction_weight: [1.5, 3.0]
    energy_cost_weight: [0.3, 1.0]
    penalty_skipped_vehicle: [50.0, 200.0]
    reward_assigned_vehicle: [20.0, 100.0]
    
  urgency_master:
    description: "Never leave vehicles unattended"
    penalty_skipped_vehicle: [200.0, 500.0]
    energy_satisfaction_weight: [2.0, 4.0]
    reward_assigned_vehicle: [50.0, 200.0]
    energy_cost_weight: [0.1, 0.8]
    
  efficiency_demon:
    description: "Maximum throughput and assignments"
    reward_assigned_vehicle: [100.0, 200.0]
    energy_satisfaction_weight: [1.0, 3.0]
    penalty_skipped_vehicle: [20.0, 100.0]
    energy_cost_weight: [0.2, 1.0]
    
  adaptive_genius:
    description: "Intelligent and flexible behavior"
    energy_satisfaction_weight: [1.0, 4.0]
    energy_cost_weight: [0.2, 1.5]
    penalty_skipped_vehicle: [30.0, 300.0]
    reward_assigned_vehicle: [10.0, 150.0]
    
  extreme_optimizer:
    description: "Radical configuration for special cases"
    energy_satisfaction_weight: [0.5, 5.0]
    energy_cost_weight: [0.01, 2.0]
    penalty_skipped_vehicle: [5.0, 500.0]
    reward_assigned_vehicle: [1.0, 200.0]